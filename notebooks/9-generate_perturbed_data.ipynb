{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook aims to study of the influence of natural perturbations under increasing severity levels.\n",
    "We first demonstrate some perturbed image samples under different perturbation functions and severity levels. Then we study the influence on model/detector performance and robustness metrics of natural perturbations under increasing severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "from utils.attackers import build_attacker\n",
    "from utils.test_utils import setup_seed\n",
    "from utils.dataloader import load_dataset\n",
    "from utils.visualize import *\n",
    "\n",
    "# Load configs: benchmarks, model variants, OoD datasets and save directory.\n",
    "with open('config.yaml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    \n",
    "score_functions = configs[\"score_functions\"]\n",
    "perturb_functions = configs[\"perturb_functions\"]\n",
    "batch_size = configs[\"batch_size\"]\n",
    "device = configs[\"device\"]\n",
    "rand_seed = configs[\"rand_seed\"]\n",
    "data_dir = configs[\"datadir\"]\n",
    "severity = configs[\"severity\"]\n",
    "\n",
    "# Define the order of perturbation functions and model variants in visualizations.\n",
    "perturb_function_sorter = [\"rotation\", \"translation\", \"scale\", \"hue\", \"saturation\", \"bright_contrast\", \"blur\", \"Linf\", \"L2\", \"average\"]\n",
    "variant_sorter = [\"NT\", \"DA\", \"AT\", \"PAT\"]\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "print(\"device:\", device)\n",
    "setup_seed(rand_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Demonstration of perturbed samples under increasing levels of perturbation severity.\n",
    "We randomly select 5 ID samples from each benchmark (CIFAR10, ImageNet100) and demonstrate the corresponding perturbed samples under increasing levels of perturbation severity. The example images are saved in `results/eval/severity_levels/perturbed_samples_demo/` folder.\n",
    "\n",
    "- The severity level is defined as 1-5.\n",
    "- We consider 9 functional perturbations in 4 categories as follows:\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Category</th>\n",
    "        <th>Perturbation</th>\n",
    "        <th>Parameters</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"3\">Geometric Transformation</td>\n",
    "        <td>rotation</td>\n",
    "        <td>±[6°, 12°, 18°, 24°, 30°]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>translation</td>\n",
    "        <td>±[6°, 12°, 18°, 24°, 30°]</td>\n",
    "    </tr>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>scale</td>\n",
    "        <td>±[6%, 12%, 18%, 24%, 30%]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"3\">Colour-Shifted Function based on HSB</td>\n",
    "        <td>hue</td>\n",
    "        <td>±[0, 0.06, 0.09, 0.12, 0.15, 0.18]π</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>saturation</td>\n",
    "        <td>1±[0, 0.16, 0.32, 0.48, 0.64, 0.80]</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>bright_contrast</td>\n",
    "        <td>bright=±[0.06, 0.12, 0.18, 0.24, 0.30]<br>\n",
    "        cont=±[0.06, 0.12, 0.18, 0.24, 0.30]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Gaussian Blur</td>\n",
    "        <td>blur</td>\n",
    "        <td>CIFAR10: σ=[0.4, 0.6, 0.7, 0.8, 1.0]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_size=[5, 5, 7, 7, 9]<br>\n",
    "        ImageNet: σ=[1, 2, 3, 4, 6]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kernel_size=[9, 17, 25, 33, 49]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td rowspan=\"2\">Additive perturbation bounded by $L_p$ norm</td>\n",
    "        <td>L<sub>inf</sub> noise</td>\n",
    "        <td>CIFAR10: ε=[0.016, 0.032, 0.048, 0.064, 0.080]<br>\n",
    "        ImageNet: ε=[0.04,0.08,0.12,0.16,0.20]\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L<sub>2</sub> noise</td>\n",
    "        <td>CIFAR10: ε=[0.016, 0.032, 0.048, 0.064, 0.080]<br>\n",
    "        ImageNet: ε=[0.04, 0.08, 0.12, 0.16, 0.20]\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate the perturbed sammples under 1-5 severity levels\n",
    "save_dir = os.path.join(\"results\", \"eval\", \"severity_levels\",\"perturbed_samples_demo\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for benchmark in configs[\"benchmark\"]:\n",
    "    img_size = configs[\"benchmark\"][benchmark][\"img_size\"]\n",
    "    data_set, data_loader = load_dataset(\"dataset/\", benchmark, img_size=img_size, benchmark=benchmark, \n",
    "                                            split=\"test\", batch_size=1)\n",
    "\n",
    "    x = torch.stack([data_set[i][0] for i in torch.randint(0, len(data_set), (5,))], dim=0)\n",
    "\n",
    "    for perb_func in perturb_functions:\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=6, ncols=5, figsize=(10, 15), facecolor=\"white\")\n",
    "        axes_o = axes[0]\n",
    "        for ax, img in zip(axes_o, x):\n",
    "            img = np.transpose(img, (1,2,0))\n",
    "            if img.shape[-1] == 1:\n",
    "                img.squeeze()\n",
    "            ax.imshow(img, cmap='viridis', vmax=1.0, vmin=0.0)\n",
    "            ax.axis(\"off\")\n",
    "            if ax is axes_o[0]:\n",
    "                ax.set_title(\"Original image\")\n",
    "\n",
    "        for severity_level in range(1, 6):\n",
    "\n",
    "            attacker = build_attacker(perb_func, severity_level, benchmark=benchmark)\n",
    "            x_perb = attacker.random_perturb(x, n_repeat=1, device=device)\n",
    "\n",
    "            axes_s = axes[severity_level]\n",
    "            for ax, img in zip(axes_s, x_perb):\n",
    "                img = np.transpose(img, (1,2,0))\n",
    "                if img.shape[-1] == 1:\n",
    "                    img.squeeze()\n",
    "                ax.imshow(img, cmap='viridis', vmax=1.0, vmin=0.0)\n",
    "                ax.axis(\"off\")\n",
    "                if ax is axes_s[0]:\n",
    "                    params = {k: v for k, v in attacker.__dict__.items() if v != 0}\n",
    "                    ax.set_title(f\"Severity level {severity_level}, \\nparameters: {params}\",\n",
    "                                 loc=\"left\")\n",
    "\n",
    "        plt.suptitle(f\"Perturbation: {perb_func}. Benchmark: {benchmark}\")\n",
    "        save_path = os.path.join(save_dir, f\"{benchmark}_{perb_func}.png\")\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Generate and save perturbed samples as corrupted dataset.\n",
    "We add one of the above-mentioned natural perturbation under predefined severity (1-5 or average) to each image in the original dataset. The corrupted images are saved in `dataset/perturbed/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save perturbed samples as corrupted dataset.\n",
    "for benchmark in configs[\"benchmark\"]:\n",
    "    img_size = configs[\"benchmark\"][benchmark][\"img_size\"]\n",
    "    ood_datasets = configs[\"benchmark\"][benchmark][\"ood_datasets\"]\n",
    "    for dataset in  [benchmark] + ood_datasets:\n",
    "        print(\"Dataset: \", dataset)\n",
    "        for attacker_name in configs[\"perturb_functions\"]:\n",
    "            print(\"perturb_function: \", attacker_name)\n",
    "            attacker = build_attacker(attacker_name, severity_level=severity, img_size=img_size)\n",
    "            # Try your own dataset here by replacing load_dataset()\n",
    "            data_set, data_loader = load_dataset(data_dir, dataset_name=dataset, img_size=img_size,\n",
    "                                                 split=\"test\", benchmark=benchmark, batch_size=batch_size)\n",
    "\n",
    "            # Generate n_sampling perturbed samples from each seed\n",
    "            save_dir = os.path.join(data_dir, \"perturbed\", f\"{dataset}_{attacker_name}_{severity.replace('all', 'avg')}\")\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            idx = 0\n",
    "            for i, (x, y) in tqdm(enumerate(data_loader)):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                x_perb = attacker.random_perturb(x, n_repeat=1, seed=rand_seed, device=device)\n",
    "                if i == 0:\n",
    "                    save_image(x_perb[:8], os.path.join(save_dir, \"demo.png\"))\n",
    "\n",
    "                for x_p, y_p in zip(x_perb, y):\n",
    "                    cls_save_dir = os.path.join(save_dir, str(y_p.item()))\n",
    "                    os.makedirs(cls_save_dir, exist_ok=True)\n",
    "                    img_save_path = os.path.join(cls_save_dir, f\"{idx}.png\")\n",
    "                    if not os.path.exists(img_save_path):\n",
    "                        save_image(x_p, img_save_path)\n",
    "                    idx += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
