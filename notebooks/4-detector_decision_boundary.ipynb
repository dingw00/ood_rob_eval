{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook aims to visualize the decision boundary of the OoD detectors.\n",
    "We use PCA and T-SNE dimension reduction techniques to visualize the logit embeddings in 2D. The distribution of OoD scores in the input space is approximated with contour maps, and the decision boundary is demonstrated with black dashed contour lines. \n",
    "\n",
    "We inspect the decision boundary of 12 OoD detectors on the CIFAR10 benchmark connected to 2 model architectures, i.e. WRN-40-2 and ResNet50, and with 4 variants (NT, DA, AT, PAT) respectively. The contour maps are saved in the `results/eval/detector_decision_boundary/` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "from models.model_utils import InputNormalizer, load_model\n",
    "from utils.dataloader import load_dataset\n",
    "from utils.eval import *\n",
    "from utils.visualize import *\n",
    "\n",
    "# Load configs: benchmarks, model variants, OoD datasets and save directory.\n",
    "with open('config.yaml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    \n",
    "score_functions = configs[\"score_functions\"]\n",
    "perturb_functions = configs[\"perturb_functions\"]\n",
    "rand_seed = configs[\"rand_seed\"]\n",
    "batch_size = configs[\"batch_size\"]\n",
    "\n",
    "# Define the order of perturbation functions and model variants in visualizations.\n",
    "perturb_function_sorter = configs[\"perturb_functions\"]\n",
    "variant_sorter = [\"NT\", \"DA\", \"AT\", \"PAT\"]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "if configs[\"device\"] == \"cuda\" and torch.cuda.is_available():\n",
    "    device = torch.device(configs[\"device\"])\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary visualizaion settings\n",
    "n_ood = 1000\n",
    "benchmark = \"CIFAR10\"\n",
    "ood_dataset = \"SVHN\"\n",
    "img_size = configs[\"benchmark\"][benchmark][\"img_size\"]\n",
    "n_classes = configs[\"benchmark\"][benchmark][\"num_classes\"]\n",
    "label_class_dict = {0: 'ID - airplanes', 1: 'ID - cars', 2: 'ID - birds', 3: 'ID - cats', \n",
    "                    4: 'ID - deer', 5: 'ID - dogs', 6: 'ID - frogs', 7: 'ID - horses', \n",
    "                    8: 'ID - ships', 9: 'ID - trucks', -1: f'OoD - {ood_dataset}'}\n",
    "\n",
    "pca = PCA(n_components=2, random_state=rand_seed)\n",
    "tsne = TSNE(n_components=2, random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision boundary of OoD detectors on the 2D representations of ID & OoD logit embeddings.\n",
    "for model_name in configs[\"benchmark\"][benchmark][\"model\"]:\n",
    "    for variant, weight_name in configs[\"benchmark\"][benchmark][\"model\"][model_name].items():\n",
    "\n",
    "        # Load model\n",
    "        weight_path = f\"./models/{benchmark.lower()}/state_dicts/{weight_name}\"\n",
    "        model = load_model(model_name, weight_path, benchmark, device=device)\n",
    "        model.eval()\n",
    "        input_normalizer = InputNormalizer(benchmark=benchmark, model_arch=model_name, \n",
    "                                        model_weight=weight_name)\n",
    "        print(\"mean:\", input_normalizer.mean.view(-1), \"\\nstd:\", input_normalizer.std.view(-1))\n",
    "\n",
    "        # Load dataset\n",
    "        id_test_data_set, id_test_data_loader = load_dataset(\"dataset/\", benchmark, img_size=img_size, benchmark=benchmark, \n",
    "                                                             shuffle=False,\n",
    "                                                split=\"test\", batch_size=batch_size, normalize=True,\n",
    "                                                mean=input_normalizer.mean.view(-1), std=input_normalizer.std.view(-1))\n",
    "\n",
    "        ood_test_data_set, ood_test_data_loader = load_dataset(\"dataset/\", ood_dataset, img_size=img_size, benchmark=benchmark, \n",
    "                                                               shuffle=False,\n",
    "                                                split=\"test\", batch_size=batch_size, normalize=True,\n",
    "                                                mean=input_normalizer.mean.view(-1), std=input_normalizer.std.view(-1))        \n",
    "\n",
    "\n",
    "        # Load OoD scores on ID & OoD test dataset from raw experiment result files.\n",
    "        df_id_scores = pd.DataFrame()\n",
    "        df_ood_scores = pd.DataFrame()\n",
    "        id_rlt_path = os.path.join(\"results\", benchmark.lower(), str(rand_seed), model_name, variant, \n",
    "                                benchmark, \"scores\", \"temp_all_scores.csv\")\n",
    "\n",
    "        ood_rlt_path = os.path.join(\"results\", benchmark.lower(), str(rand_seed), model_name, variant, \n",
    "                                ood_dataset, \"scores\", \"temp_scores.csv\")\n",
    "        if (not os.path.exists(id_rlt_path)) or (not os.path.exists(ood_rlt_path)):\n",
    "            print(f\"File not found: {id_rlt_path} or {ood_rlt_path}.\")\n",
    "            continue\n",
    "\n",
    "        df_id_scores = pd.read_csv(id_rlt_path).copy()\n",
    "        df_ood_scores = pd.read_csv(ood_rlt_path).copy()\n",
    "\n",
    "        # Test the DNN model & OoD detectors on ID & OoD dataset and record the logit embeddings.\n",
    "        id_logits = torch.empty(0, n_classes)\n",
    "        with torch.no_grad():\n",
    "            for x, y in id_test_data_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                id_logits = torch.cat((id_logits, logits.cpu()), dim=0)\n",
    "\n",
    "        idx = df_ood_scores[\"idx\"].values\n",
    "        ood_test_data_set = [ood_test_data_set[i] for i in idx]\n",
    "        ood_test_data_loader = DataLoader(ood_test_data_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        ood_logits = torch.empty(0, n_classes)\n",
    "        with torch.no_grad():\n",
    "            for x, y in ood_test_data_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                ood_logits = torch.cat((ood_logits, logits.cpu()), dim=0)\n",
    "\n",
    "        # Dimension reduction on the ID & OoD logit embeddings using PCA and T-SNE methods.\n",
    "        all_logits = torch.cat((id_logits, ood_logits), dim=0)\n",
    "        logits_pca = pca.fit_transform(all_logits.numpy())\n",
    "        logits_tsne = tsne.fit_transform(all_logits.numpy())\n",
    "\n",
    "        # Assembly OoD scores and 2D embedding representations for visualization.\n",
    "        df_logits_pca = pd.DataFrame(logits_pca, columns=[\"pca_1\", \"pca_2\"])\n",
    "        df_logits_tsne = pd.DataFrame(logits_tsne, columns=[\"tsne_1\", \"tsne_2\"])\n",
    "        df_id_scores[\"dataset\"] = \"ID\"\n",
    "        df_ood_scores[\"dataset\"] = \"OoD\"\n",
    "        df_all = pd.concat([df_id_scores, df_ood_scores], axis=0).reset_index(drop=True).copy()\n",
    "        df_all = pd.concat([df_all, df_logits_pca, df_logits_tsne], axis=1).copy()\n",
    "        df_all[\"class\"] = df_all[\"y_true\"].apply(lambda x: label_class_dict[x])\n",
    "\n",
    "        # Inspect the visualization clarity of PCA and T-SNE dimension reduction methods.\n",
    "        fig, axes = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "        axes = axes.flatten()\n",
    "        for ax, method in zip(axes, [\"pca\", \"tsne\"]):\n",
    "            sns.scatterplot(data=df_all, x=f\"{method}_1\", y=f\"{method}_2\", hue=\"class\", style=\"dataset\", ax=ax)\n",
    "            ax.set_title(f\"Method={method.upper()}\")\n",
    "            ax.legend(loc=\"upper right\")\n",
    "        plt.suptitle(f\"PCA & T-SNE visualization of ID & OoD samples.\\nModel={model_name}, Variant={variant}\")\n",
    "        plt.show() # The visualization of PCA is not clear enough to distinguish ID and OoD samples.\n",
    "        plt.close(\"all\")\n",
    "\n",
    "        # Visualize the OoD scores distribution and the decision boundary of 12 OoD detectors on the \n",
    "        # 2D embeddings using contour maps.\n",
    "        save_dir = os.path.join(\"results\", \"eval\", \"detector_decision_boundary\", f\"{benchmark.lower()}_{model_name}_{variant}\")\n",
    "        for score_func in score_functions:\n",
    "            if f\"{score_func}_score\" not in df_id_scores.columns or f\"{score_func}_score\" not in df_ood_scores.columns:\n",
    "                continue\n",
    "\n",
    "            id_scores = df_id_scores[f\"{score_func}_score\"].to_numpy()\n",
    "            ood_scores = df_ood_scores[f\"{score_func}_score\"].to_numpy()\n",
    "            auroc, aupr_in, aupr_out, fpr, threshold, fpr_out, threshold_out = get_ood_measures(id_scores, ood_scores)\n",
    "\n",
    "            interpol_contour(df_all[\"tsne_1\"], df_all[\"tsne_2\"], df_all[f\"{score_func}_score\"], \n",
    "                            title=f\"OoD detector's decision boundary\\nDetector={score_func}, threshold={round(-threshold, 3)}\", \n",
    "                            s=3,\n",
    "                            true_labels=df_all[\"y_true\"], marker_mask=df_all[\"dataset\"], marker_panel={\"ID\": \"o\", \"OoD\": \"x\"},\n",
    "                            thresholds=[-threshold], label_class_dict=label_class_dict, \n",
    "                            save_path=os.path.join(save_dir, f\"detector_decision_boundary_{score_func}.png\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
