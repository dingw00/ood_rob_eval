{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The choices for each index column are listed below:\n",
    "- benchmark: \n",
    "    - CIFAR10\n",
    "    - Imagenet100\n",
    "- data:\n",
    "    - ID\n",
    "    - OoD\n",
    "- dataset\n",
    "    - CIFAR10, Textures, SVHN, LSUN-C, LSUN-R, iSUN, Places365, average\n",
    "    - Imagenet100, NINCO, Textures, iNaturalist, SUN, Places, average\n",
    "- model: \n",
    "    - wrn_40_2\n",
    "    - resnet50\n",
    "- variant: \n",
    "    - NT\n",
    "    - DA\n",
    "    - AT\n",
    "    - PAT\n",
    "- detector:\n",
    "    - Entropy\n",
    "    - ViM\n",
    "    - Mahalanobis+ODIN\n",
    "    - Mahalanobis\n",
    "    - KLMatching\n",
    "    - SHE\n",
    "    - MSP\n",
    "    - EnergyBased\n",
    "    - MaxLogit\n",
    "    - ODIN\n",
    "    - DICE\n",
    "    - RMD\n",
    "- perturb_function:\n",
    "    - rotation\n",
    "    - translation\n",
    "    - scale\n",
    "    - hue\n",
    "    - saturation\n",
    "    - bright_contrast\n",
    "    - blur  \n",
    "    - Linf\n",
    "    - L2\n",
    "    - average\n",
    "- severity: 1, 2, 3, 4, 5, average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Load configs: benchmarks, model variants, OoD datasets and save directory.\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "sorters = dict(benchmark=[\"CIFAR10\", \"Imagenet100\", \"Imagenet1k\"], model=[\"wrn_40_2\", \"resnet50\", \"swin\", \"deit\", \"vit\"],\n",
    "                    variant=[\"NT\", \"DA\", \"AT\", \"PAT\"], detector=configs[\"score_functions\"],\n",
    "                    data=[\"ID\", \"OoD\"], \n",
    "                    perturb_function=[\"average\"]+configs[\"perturb_functions\"])\n",
    "\n",
    "\n",
    "# Read the DAE summary file\n",
    "filepath = os.path.join(\"../results/eval/robustness\", \"dae_summary.csv\")\n",
    "df_dae = pd.read_csv(filepath).copy()\n",
    "# display(df_dae)\n",
    "\n",
    "# Read the model accuracy and FPR95 summary file\n",
    "filepath = os.path.join(\"../results/eval/performance\", \"model_performance.csv\")\n",
    "df_mdl = pd.read_csv(filepath).copy()\n",
    "filepath = os.path.join(\"../results/eval/performance\", \"detector_performance.csv\")\n",
    "df_detector = pd.read_csv(filepath).copy()\n",
    "df_detector = df_detector.query(\"dataset=='average'\").drop(columns=[\"dataset\", \"AUROC\", \"AUPR_IN\", \"AUPR_OUT\"]).\\\n",
    "    rename(columns={\"score_function\": \"detector\"}).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Overview of the DAE rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the DAE rate\n",
    "# Search for related experiment results\n",
    "df_filtered = df_dae[\n",
    "                #  (df_dae[\"variant\"].isin([\"NT\", \"DA\"])) &\n",
    "                #  (df_dae[\"detector\"]==\"ODIN\") &\n",
    "                #  (df_dae[\"data\"]==\"OoD\") &\n",
    "                 (df_dae[\"perturb_function\"]==\"average\") &\n",
    "                 (df_dae[\"dataset\"].isin([\"average\", \"CIFAR10\", \"Imagenet100\", \"Imagenet1k\"]))\n",
    "                ].drop([\"dataset\", \"perturb_function\"], axis=1).copy()\n",
    "df_perf = pd.merge(left=df_mdl, right=df_detector, on=[\"benchmark\", \"model\", \"variant\"], how=\"inner\")\n",
    "df_perf_dae = pd.merge(left=df_perf, right=df_filtered, on=[\"benchmark\", \"model\", \"variant\", \"detector\"], how=\"inner\")\n",
    "df_rlt = df_perf_dae.pivot(index=[\"benchmark\", \"model\", \"variant\", \"accuracy\", \"detector\", \"FPR95\",], \n",
    "                           columns=[\"data\"])\n",
    "df_rlt[\"ID_DAE\"] = df_rlt[(\"dae_mean\", \"ID\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"ID\")].astype(str)\n",
    "df_rlt[\"OOD_DAE\"] = df_rlt[(\"dae_mean\", \"OoD\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"OoD\")].astype(str)\n",
    "df_rlt[\"MAE\"] = df_rlt[(\"mae_mean\", \"ID\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"mae_std\", \"ID\")].astype(str)\n",
    "df_rlt = df_rlt[[\"ID_DAE\", \"OOD_DAE\", \"MAE\"]]\n",
    "df_rlt.columns = df_rlt.columns.droplevel([1])\n",
    "df_rlt.set_index(\"MAE\", append=True, inplace=True)\n",
    "df_rlt = df_rlt.reorder_levels([\"benchmark\", \"model\", \"variant\", \"accuracy\", \"MAE\", \"detector\", \"FPR95\"]).reset_index()\n",
    "\n",
    "df_rlt_baseline = df_rlt[df_rlt[\"detector\"]==\"MSP\"]\n",
    "df_rlt = df_rlt.sort_values(by=\"FPR95\")\n",
    "df_rlt = df_rlt.groupby(by=[\"benchmark\", \"model\", \"variant\", \"accuracy\", \"MAE\"]).head(3)\n",
    "df_rlt = pd.concat([df_rlt, df_rlt_baseline], axis=0).copy()\n",
    "\n",
    "for sort_col in [\"benchmark\", \"model\", \"variant\"]:\n",
    "    df_rlt[sort_col] = df_rlt[sort_col].astype(\"category\")\n",
    "    df_rlt[sort_col] = df_rlt[sort_col].cat.set_categories(sorters[sort_col], ordered=True)\n",
    "df_rlt.sort_values(by=[\"benchmark\", \"model\", \"variant\", \"FPR95\"], inplace=True)\n",
    "df_rlt.set_index([\"benchmark\", \"model\", \"variant\", \"accuracy\", \"MAE\", \"detector\", \"FPR95\"], inplace=True, drop=True)\n",
    "display(df_rlt)\n",
    "# df_rlt.to_csv(\"DAE_overview_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show DA improvement from NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DA improvement from NT\n",
    "\n",
    "# Search for related experiment results\n",
    "df_filtered = df_dae[\n",
    "                #  (df_dae[\"variant\"].isin([\"NT\", \"DA\"])) &\n",
    "                #  (df_dae[\"detector\"]==\"ODIN\") &\n",
    "                #  (df_dae[\"data\"]==\"OoD\") &\n",
    "                 (df_dae[\"perturb_function\"]==\"average\") &\n",
    "                 (df_dae[\"dataset\"].isin([\"average\", \"CIFAR10\", \"Imagenet100\"]))\n",
    "                ].copy()\n",
    "\n",
    "df_filtered.drop([\"dataset\", \"perturb_function\", \"mae_mean\", \"mae_std\"], axis=1, inplace=True)\n",
    "for sort_col in [\"benchmark\", \"model\", \"detector\", \"variant\", \"data\"]:\n",
    "    df_filtered[sort_col] = df_filtered[sort_col].astype(\"category\")\n",
    "    df_filtered[sort_col] = df_filtered[sort_col].cat.set_categories(sorters[sort_col], ordered=True)\n",
    "df_filtered.sort_values(by=[\"benchmark\", \"model\", \"detector\", \"variant\", \"data\"], inplace=True)\n",
    "\n",
    "df_rlt = df_filtered.pivot(index=[\"benchmark\", \"model\", \"detector\"], columns=[\"variant\", \"data\", ])\n",
    "df_rlt[\"ID_NT_DAE\"] = df_rlt[(\"dae_mean\", \"NT\", \"ID\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"NT\", \"ID\")].astype(str)\n",
    "df_rlt[\"ID_DA_DAE\"] = df_rlt[(\"dae_mean\", \"DA\", \"ID\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"DA\", \"ID\")].astype(str)\n",
    "df_rlt[\"OOD_NT_DAE\"] = df_rlt[(\"dae_mean\", \"NT\", \"OoD\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"NT\", \"OoD\")].astype(str)\n",
    "df_rlt[\"OOD_DA_DAE\"] = df_rlt[(\"dae_mean\", \"DA\", \"OoD\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"DA\", \"OoD\")].astype(str)\n",
    "df_rlt = df_rlt[[\"ID_NT_DAE\", \"ID_DA_DAE\", \"OOD_NT_DAE\", \"OOD_DA_DAE\"]]\n",
    "df_rlt.columns = df_rlt.columns.droplevel([1,2])\n",
    "\n",
    "def highlighter(x):\n",
    "    s1 = \"color: blue;\" if float(x[\"ID_NT_DAE\"].split(u\"\\u00B1\")[0]) < float(x[\"ID_DA_DAE\"].split(u\"\\u00B1\")[0]) else \"color: red;\"\n",
    "    s2 = \"color: blue;\" if float(x[\"OOD_NT_DAE\"].split(u\"\\u00B1\")[0]) < float(x[\"OOD_DA_DAE\"].split(u\"\\u00B1\")[0]) else \"color: red;\"\n",
    "    return [\"\"]+[s1] + [\"\"]+[s2]\n",
    "    \n",
    "    \n",
    "df_rlt = df_rlt.style.apply(highlighter, axis=1)\n",
    "display(df_rlt)\n",
    "# df_rlt.to_latex(\"DA_DAE_table.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of DAE rate under 1-5 severity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DAE summary file\n",
    "filepath = os.path.join(\"../results/eval/severity_levels/robustness\", \"dae_summary.csv\")\n",
    "df_dae = pd.read_csv(filepath).copy()\n",
    "\n",
    "df_filtered = df_dae[\n",
    "                #  (df_dae[\"variant\"].isin([\"NT\", \"DA\"])) &\n",
    "                #  (df_dae[\"detector\"]==\"ODIN\") &\n",
    "                #  (df_dae[\"data\"]==\"OoD\") &\n",
    "                 (df_dae[\"perturb_function\"]==\"average\") &\n",
    "                 (df_dae[\"dataset\"].isin([\"average\", \"CIFAR10\", \"Imagenet100\"]))\n",
    "                ].drop([\"dataset\", \"perturb_function\"], axis=1).copy()\n",
    "df_perf = pd.merge(left=df_mdl, right=df_detector, on=[\"benchmark\", \"model\", \"variant\"], how=\"inner\")\n",
    "df_perf_dae = pd.merge(left=df_perf, right=df_filtered, on=[\"benchmark\", \"model\", \"variant\", \"detector\"], how=\"inner\")\n",
    "df_rlt = df_perf_dae.pivot(index=[\"benchmark\", \"model\", \"variant\", \"accuracy\", \"detector\", \"FPR95\", \"severity\"], \n",
    "                           columns=[\"data\"])\n",
    "\n",
    "df_rlt[\"ID_DAE\"] = df_rlt[(\"dae_mean\", \"ID\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"ID\")].astype(str)\n",
    "df_rlt[\"OOD_DAE\"] = df_rlt[(\"dae_mean\", \"OoD\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"dae_std\", \"OoD\")].astype(str)\n",
    "df_rlt[\"MAE\"] = df_rlt[(\"mae_mean\", \"ID\")].astype(str)+u\"\\u00B1\"+ df_rlt[(\"mae_std\", \"ID\")].astype(str)\n",
    "df_rlt = df_rlt[[\"ID_DAE\", \"OOD_DAE\", \"MAE\"]]\n",
    "df_rlt.columns = df_rlt.columns.droplevel([1])\n",
    "df_rlt.set_index(\"MAE\", append=True, inplace=True)\n",
    "df_rlt = df_rlt.reorder_levels([\"benchmark\", \"model\", \"variant\", \"accuracy\", \"MAE\", \"detector\", \"FPR95\", \"severity\"]).reset_index()\n",
    "\n",
    "df_rlt_baseline = df_rlt[df_rlt[\"detector\"]==\"MSP\"]\n",
    "df_rlt = df_rlt.sort_values(by=\"FPR95\")\n",
    "df_rlt = df_rlt.groupby(by=[\"benchmark\", \"model\", \"variant\", \"accuracy\", \"MAE\"]).head(3)\n",
    "df_rlt = pd.concat([df_rlt, df_rlt_baseline], axis=0).copy()\n",
    "\n",
    "for sort_col in [\"benchmark\", \"model\", \"variant\"]:\n",
    "    df_rlt[sort_col] = df_rlt[sort_col].astype(\"category\")\n",
    "    df_rlt[sort_col] = df_rlt[sort_col].cat.set_categories(sorters[sort_col], ordered=True)\n",
    "df_rlt.sort_values(by=[\"benchmark\", \"model\", \"variant\", \"FPR95\", \"severity\"], inplace=True)\n",
    "df_rlt.set_index([\"benchmark\", \"model\", \"variant\", \"accuracy\", \"detector\", \"FPR95\", \"severity\", \"MAE\"], inplace=True, drop=True)\n",
    "display(df_rlt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
