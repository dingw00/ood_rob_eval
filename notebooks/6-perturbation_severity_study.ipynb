{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook aims to study of the influence of natural perturbations under increasing severity levels.\n",
    "We first demonstrate some perturbed image samples under different perturbation functions and severity levels. Then we study the influence on model/detector performance and robustness metrics of natural perturbations under increasing severity levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "print(\"Current working directory: \", os.getcwd())\n",
    "\n",
    "from utils.attackers import build_attacker\n",
    "from utils.test_utils import setup_seed\n",
    "from utils.dataloader import load_dataset\n",
    "from utils.visualize import *\n",
    "\n",
    "# Load configs: benchmarks, model variants, OoD datasets and save directory.\n",
    "with open('config.yaml', 'r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    \n",
    "score_functions = configs[\"score_functions\"]\n",
    "perturb_functions = configs[\"perturb_functions\"]\n",
    "rand_seed = configs[\"rand_seed\"]\n",
    "\n",
    "\n",
    "# Define the order of perturbation functions and model variants in visualizations.\n",
    "perturb_function_sorter = [\"rotation\", \"translation\", \"scale\", \"hue\", \"saturation\", \"bright_contrast\", \"blur\", \"Linf\", \"L2\", \"average\"]\n",
    "variant_sorter = [\"NT\", \"DA\", \"AT\", \"PAT\"]\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Model / detector robustness under increasing levels of perturbation severity.\n",
    "For each perturbation, we demonstrate the MAE/DAE rate with increasing levels of severity.\n",
    "\n",
    "The visualization is in the format of line charts. All the statistics can be inspected in the tables generated in `results/eval/severity_levels/robustness/` folders. The generated figures are saved in `results/eval/severity_levels/robustness/figures/` folder.\n",
    "\n",
    "- The severity level is 1-5 as demonstrated in the Cell 3-4.\n",
    "- We consider different OoD detectors and various perturbations.\n",
    "- We compare among different model variants (NT, DA, AT, PAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_dir = os.path.join(\"results\", \"eval\", \"severity_levels\", \"robustness\")\n",
    "save_dir = os.path.join(\"results\", \"eval\", \"severity_levels\", \"robustness\", \"figures\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, \"perturbations\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(save_dir, \"detectors\"), exist_ok=True)\n",
    "\n",
    "for benchmark in configs[\"benchmark\"]:\n",
    "    \n",
    "    # ID dataset\n",
    "    # Load the MAE/DAE rate table on ID dataset.\n",
    "    df_id = None\n",
    "    file_path = os.path.join(robustness_dir, f\"{benchmark.lower()}_id_local_mae_dae_rate_mean_std.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df_id = pd.read_csv(file_path).copy()\n",
    "        \n",
    "        df_id[\"perturb_function\"] = df_id[\"perturb_function\"].astype(\"category\")\n",
    "        df_id[\"perturb_function\"] = df_id[\"perturb_function\"].cat.set_categories(perturb_function_sorter, ordered=True)\n",
    "        df_id[\"variant\"] = df_id[\"variant\"].astype(\"category\")\n",
    "        df_id[\"variant\"] = df_id[\"variant\"].cat.set_categories(variant_sorter, ordered=True)\n",
    "    \n",
    "    # OOD dataset\n",
    "    # Load the DAE rate table on OoD dataset.\n",
    "    df_ood = None\n",
    "    file_path = os.path.join(robustness_dir, f\"{benchmark.lower()}_ood_local_dae_rate_mean_std.csv\")\n",
    "    if os.path.exists(file_path):\n",
    "        df_ood = pd.read_csv(file_path).copy()\n",
    "    \n",
    "        df_ood[\"perturb_function\"] = df_ood[\"perturb_function\"].astype(\"category\")\n",
    "        df_ood[\"perturb_function\"] = df_ood[\"perturb_function\"].cat.set_categories(perturb_function_sorter, ordered=True)\n",
    "        df_ood[\"variant\"] = df_ood[\"variant\"].astype(\"category\")\n",
    "        df_ood[\"variant\"] = df_ood[\"variant\"].cat.set_categories(variant_sorter, ordered=True)\n",
    "\n",
    "    if (df_id is not None) and (df_ood is not None):\n",
    "\n",
    "        for model_name in configs[\"benchmark\"][benchmark][\"model\"]:\n",
    "\n",
    "            df_ood_ = df_ood[(df_ood[\"model\"]==model_name) & (df_ood[\"dataset\"]==\"average\")].copy()\n",
    "            df_ood_[\"dataset\"] = \"OoD\"\n",
    "            df_id_ = df_id[(df_id[\"model\"]==model_name)].copy()\n",
    "            df_id_[\"dataset\"] = \"ID\"\n",
    "\n",
    "            data = pd.concat([df_id_, df_ood_], axis=0).copy()\n",
    "            data = data.sort_values(by=[\"perturb_function\", \"variant\", \"severity\"]).copy()\n",
    "            data = data[data[\"severity\"]!=\"average\"].copy()\n",
    "            if len(data) == 0:\n",
    "                continue\n",
    "            perturb_functions = data[\"perturb_function\"].unique()\n",
    "            \n",
    "            # MAE rate - severity level plot\n",
    "            # ax=perturb_function\n",
    "            n_cols = 3\n",
    "            n_rows = int(np.ceil(len(perturb_functions) / float(n_cols)))\n",
    "            fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "            axes = axes.flatten()\n",
    "            for ax_i, ax in enumerate(axes):\n",
    "                if ax_i < len(perturb_functions):\n",
    "                    perturb_func = perturb_functions[ax_i]\n",
    "                    data_i = data[(data[\"perturb_function\"]==perturb_func) & (data[\"dataset\"]==\"ID\")].copy()\n",
    "                    sns.lineplot(data=data_i, x=\"severity\", y=\"mae_mean\", hue=\"variant\", ax=ax, style=\"variant\", marker=\"o\")\n",
    "                    \n",
    "                    # # Demonstrate the standard deviation of DAE rate.\n",
    "                    # for v in data_i[\"variant\"].unique():\n",
    "                    #     data_v = data_i[data_i[\"variant\"]==v].copy()\n",
    "                    #     ax.fill_between(data_v[\"severity\"].to_numpy(), \n",
    "                    #                     data_v[\"mae_mean\"]+data_v[\"mae_std\"].to_numpy(), \n",
    "                    #                     data_v[\"mae_mean\"]-data_v[\"mae_std\"].to_numpy(), alpha=0.1)\n",
    "                    \n",
    "                    ax.set_xlim(0, 4.2)\n",
    "                    ax.set_title(f\"Perturbation={perturb_func}\")\n",
    "                    ax.set_ylabel(\"MAE rate (%)\")\n",
    "                    ax.set_xlabel(\"Severity level\")\n",
    "                    ax.legend(loc=\"upper left\", ncols=2)\n",
    "\n",
    "            plt.suptitle(f\"Model robustness - MAE rate with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}\")\n",
    "            plt.savefig(os.path.join(save_dir, f\"{benchmark.lower()}_{model_name}_mae_severity.png\"))\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            # ID & OoD DAE rate - severity level plot under different perturbations.\n",
    "            for score_func in score_functions:\n",
    "                # ax=perturb_function\n",
    "                n_cols = 3\n",
    "                n_rows = int(np.ceil(len(perturb_functions) / float(n_cols)))\n",
    "                fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "                axes = axes.flatten()\n",
    "                for ax_i, ax in enumerate(axes):\n",
    "                    if ax_i < len(perturb_functions):\n",
    "                        perturb_func = perturb_functions[ax_i]\n",
    "                        data_i = data[data[\"perturb_function\"]==perturb_func].copy()\n",
    "                        sns.lineplot(data=data_i, x=\"severity\", y=f\"dae_{score_func}_mean\", hue=\"dataset\", style=\"variant\", ax=ax, marker=\"o\")\n",
    "                        # # Demonstrate the standard deviation of DAE rate.\n",
    "                        # for v in data_i[\"variant\"].unique():\n",
    "                        #     for dataset in data_i[\"dataset\"].unique():\n",
    "                        #         data_v = data_i[(data_i[\"variant\"]==v) & (data_i[\"dataset\"]==dataset)].copy()\n",
    "                        #         ax.fill_between(data_v[\"severity\"].to_numpy(), \n",
    "                        #                         data_v[f\"dae_{score_func}_mean\"]+data_v[f\"dae_{score_func}_std\"].to_numpy(), \n",
    "                        #                         data_v[f\"dae_{score_func}_mean\"]-data_v[f\"dae_{score_func}_std\"].to_numpy(), alpha=0.1)\n",
    "                        ax.set_title(f\"Perturbation={perturb_func}\")\n",
    "                        ax.set_ylabel(\"DAE rate (%)\")\n",
    "                        ax.set_xlabel(\"Severity level\")\n",
    "                        ax.set_xlim(0, 4.2)\n",
    "                        ax.legend(loc=\"upper left\", ncols=2)\n",
    "                    else:\n",
    "                        ax.axis(\"off\")\n",
    "\n",
    "                plt.suptitle(f\"OoD Detector robustness - DAE rate with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}, OoD detector={score_func}\")\n",
    "                plt.savefig(os.path.join(save_dir, \"perturbations\", f\"{benchmark.lower()}_{model_name}_{score_func}_dae_severity.png\"))\n",
    "                plt.close(\"all\")\n",
    "            \n",
    "            # ID & OoD DAE rate - severity level plot for different OoD detectors.\n",
    "            for perb_func in perturb_functions:\n",
    "                n_cols = 3\n",
    "                n_rows = int(np.ceil(len(score_functions) / float(n_cols)))\n",
    "                fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "                axes = axes.flatten()\n",
    "                data_ = data[data[\"perturb_function\"]==perb_func].copy()\n",
    "                for ax_i, ax in enumerate(axes):\n",
    "                    if ax_i < len(score_functions):\n",
    "                        score_func = score_functions[ax_i]\n",
    "                        sns.lineplot(data=data_, x=\"severity\", y=f\"dae_{score_func}_mean\", hue=\"dataset\", style=\"variant\", ax=ax, marker=\"o\")\n",
    "                        ax.set_title(f\"Detector={score_func}\")\n",
    "                        ax.set_ylabel(\"DAE rate (%)\")\n",
    "                        ax.set_xlabel(\"Severity level\")\n",
    "                        ax.set_xlim(0, 4.2)\n",
    "                        ax.legend(loc=\"upper left\", ncols=2)\n",
    "                    else:\n",
    "                        ax.axis(\"off\")\n",
    "\n",
    "                plt.suptitle(f\"OoD Detector robustness - DAE rate with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}, Perturbation={perb_func}\")\n",
    "                plt.savefig(os.path.join(save_dir, \"detectors\", f\"{benchmark.lower()}_{model_name}_{perb_func}_dae_severity.png\"))\n",
    "                plt.close(\"all\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model / detector performance under incresing levels of perturbation severity.\n",
    "For each perturbation, we demonstrate the model accuracy / detector FPR95/AUROC/AUPR with increasing levels of severity.\n",
    "\n",
    "The visualization is in the format of line charts. All the statistics can be inspected in the tables generated in `results/eval/severity_levels/performance/` folder. The generated figures are saved in `results/eval/severity_levels/performance/figures/` folder.\n",
    "\n",
    "- The severity level is 1-5 as demonstrated in the Cell 3-4.\n",
    "- We consider different OoD detectors and various perturbations.\n",
    "- We compare among different model variants (NT, DA, AT, PAT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(\"results\", \"eval\", \"severity_levels\", \"performance\", \"figures\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load DNN model and OoD detectors' performance metrics.\n",
    "performance_dir = os.path.join(\"results\", \"eval\", \"severity_levels\", \"performance\")\n",
    "df_model_perf_seed, df_model_perf_perb, df_detector_perf_seed, df_detector_perf_perb = None, None, None, None\n",
    "file_path = os.path.join(performance_dir, \"model_performance_seed.csv\")\n",
    "if os.path.exists(file_path):\n",
    "    df_model_perf_seed = pd.read_csv(file_path).copy()\n",
    "    df_model_perf_seed = df_model_perf_seed.set_index([\"benchmark\", \"model\"])\n",
    "file_path = os.path.join(performance_dir, \"model_performance_perb.csv\")\n",
    "if os.path.exists(file_path):\n",
    "    df_model_perf_perb = pd.read_csv(file_path).copy()\n",
    "    df_model_perf_perb = df_model_perf_perb.set_index([\"benchmark\", \"model\"])\n",
    "\n",
    "file_path = os.path.join(performance_dir, \"detector_performance_seed.csv\")\n",
    "if os.path.exists(file_path):\n",
    "    df_detector_perf_seed = pd.read_csv(file_path).copy()\n",
    "    df_detector_perf_seed = df_detector_perf_seed.set_index([\"benchmark\", \"model\", \"score_function\"])\n",
    "file_path = os.path.join(performance_dir, \"detector_performance_perb.csv\")\n",
    "if os.path.exists(file_path):\n",
    "    df_detector_perf_perb = pd.read_csv(file_path).copy()\n",
    "    df_detector_perf_perb = df_detector_perf_perb.set_index([\"benchmark\", \"model\", \"score_function\"])\n",
    "\n",
    "for benchmark in configs[\"benchmark\"]:\n",
    "    \n",
    "    if (df_model_perf_seed is not None) and (df_model_perf_perb is not None):\n",
    "        \n",
    "        for model_name in configs[\"benchmark\"][benchmark][\"model\"]:\n",
    "            \n",
    "            # Model performance - severity level plot\n",
    "            if (benchmark, model_name) in df_model_perf_seed.index and (benchmark, model_name) in df_model_perf_perb.index:\n",
    "                df_model_perf_seed_ = df_model_perf_seed.loc[[(benchmark, model_name)]].copy().reset_index(drop=True)\n",
    "                df_model_perf_perb_ = df_model_perf_perb.loc[[(benchmark, model_name)]].copy().reset_index(drop=True)\n",
    "                df_model_perf_seed_[\"severity\"] = \"0 - original\"\n",
    "\n",
    "                data = df_model_perf_perb_.copy()\n",
    "                \n",
    "                perturb_functions = data[\"perturb_function\"].unique()\n",
    "                print(perturb_functions)\n",
    "                for perb_func in perturb_functions:\n",
    "                    df_model_perf_seed__ = df_model_perf_seed_.copy()\n",
    "                    df_model_perf_seed__[\"perturb_function\"] = perb_func\n",
    "                    data = pd.concat([data, df_model_perf_seed__], axis=0).copy()\n",
    "                \n",
    "                data[\"perturb_function\"] = data[\"perturb_function\"].astype(\"category\")\n",
    "                data[\"perturb_function\"] = data[\"perturb_function\"].cat.set_categories(perturb_function_sorter, ordered=True)\n",
    "                data[\"variant\"] = data[\"variant\"].astype(\"category\")\n",
    "                data[\"variant\"] = data[\"variant\"].cat.set_categories(variant_sorter, ordered=True)\n",
    "            \n",
    "                data = data[data[\"severity\"]!=\"average\"].copy()\n",
    "                data = data.sort_values(by=[\"perturb_function\", \"variant\", \"severity\"]).copy()                \n",
    "                \n",
    "                if len(data) > 0:\n",
    "                    # ax=perturb_function\n",
    "                    n_cols = 3\n",
    "                    n_rows = int(np.ceil(len(perturb_functions) / float(n_cols)))\n",
    "                    fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "                    axes = axes.flatten()\n",
    "                    for ax_i, ax in enumerate(axes):\n",
    "                        if ax_i < len(perturb_functions):\n",
    "                            perturb_func = perturb_functions[ax_i]\n",
    "                            data_i = data[(data[\"perturb_function\"]==perturb_func)].copy()\n",
    "                            sns.lineplot(data=data_i, x=\"severity\", y=\"accuracy\", hue=\"variant\", ax=ax, style=\"variant\", \n",
    "                                         marker=\"o\", errorbar=None)\n",
    "                            \n",
    "                            ax.set_title(f\"Perturbation={perturb_func}\")\n",
    "                            ax.set_ylabel(\"Model accuracy (%)\")\n",
    "                            ax.set_xlabel(\"Severity level\")\n",
    "                            ax.set_xlim(0, 5.2)\n",
    "                            ax.legend(loc=\"lower left\", ncols=4)\n",
    "                        else:\n",
    "                            ax.axis(\"off\")\n",
    "\n",
    "                    plt.suptitle(f\"Model performance - Accuracy with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}\")\n",
    "                    plt.savefig(os.path.join(save_dir, f\"{benchmark.lower()}_{model_name}_accuracy_severity.png\"))\n",
    "                    plt.close(\"all\")\n",
    "\n",
    "            for score_func in score_functions:\n",
    "                # FPR95 - severity level plot\n",
    "                if (benchmark, model_name, score_func) in df_detector_perf_seed.index and (benchmark, model_name, score_func) in df_detector_perf_perb.index:\n",
    "                    df_detector_perf_seed_ = df_detector_perf_seed.loc[[(benchmark, model_name, score_func)]].copy().reset_index(drop=True)\n",
    "                    df_detector_perf_perb_ = df_detector_perf_perb.loc[[(benchmark, model_name, score_func)]].copy().reset_index(drop=True)\n",
    "                    df_detector_perf_seed_[\"severity\"] = \"0 - original\"\n",
    "\n",
    "                    data = df_detector_perf_perb_.copy()\n",
    "                    perturb_functions = data[\"perturb_function\"].unique()\n",
    "\n",
    "                    for perb_func in perturb_functions:\n",
    "                        df_detector_perf_seed__ = df_detector_perf_seed_.copy()\n",
    "                        df_detector_perf_seed__[\"perturb_function\"] = perb_func\n",
    "                        data = pd.concat([data, df_detector_perf_seed__], axis=0).copy()\n",
    "                    \n",
    "                    data[\"perturb_function\"] = data[\"perturb_function\"].astype(\"category\")\n",
    "                    data[\"perturb_function\"] = data[\"perturb_function\"].cat.set_categories(perturb_function_sorter, ordered=True)\n",
    "                    data[\"variant\"] = data[\"variant\"].astype(\"category\")\n",
    "                    data[\"variant\"] = data[\"variant\"].cat.set_categories(variant_sorter, ordered=True)\n",
    "    \n",
    "                    data = data[(data[\"severity\"]!=\"average\") & (data[\"dataset\"]!=\"average\")].copy()\n",
    "                    data = data.sort_values(by=[\"perturb_function\", \"variant\", \"severity\"]).copy()                \n",
    "                    \n",
    "                    if len(data) > 0:\n",
    "                        # ax=perturb_function\n",
    "                        n_cols = 3\n",
    "                        n_rows = int(np.ceil(len(perturb_functions) / float(n_cols)))\n",
    "                        fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "                        axes = axes.flatten()\n",
    "                        for ax_i, ax in enumerate(axes):\n",
    "                            if ax_i < len(perturb_functions):\n",
    "                                perturb_func = perturb_functions[ax_i]\n",
    "                                data_i = data[(data[\"perturb_function\"]==perturb_func)].copy()\n",
    "                                sns.lineplot(data=data_i, x=\"severity\", y=\"FPR95\", hue=\"variant\", ax=ax, style=\"variant\", \n",
    "                                             marker=\"o\", errorbar=None)\n",
    "                                \n",
    "                                ax.set_title(f\"Perturbation={perturb_func}\")\n",
    "                                ax.set_ylabel(\"FPR95 (%)\")\n",
    "                                ax.set_xlabel(\"Severity level\")\n",
    "                                ax.set_xlim(0, 5.2)\n",
    "                                ax.legend(loc=\"lower left\", ncols=4)\n",
    "                            else:\n",
    "                                ax.axis(\"off\")\n",
    "\n",
    "                        plt.suptitle(f\"OoD Detector performance - FPR95 with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}, OoD detector={score_func}\")\n",
    "                        plt.savefig(os.path.join(save_dir, f\"{benchmark.lower()}_{model_name}_{score_func}_fpr95_severity.png\"))\n",
    "                        plt.close(\"all\")\n",
    "\n",
    "                        fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "                        axes = axes.flatten()\n",
    "                        for ax_i, ax in enumerate(axes):\n",
    "                            if ax_i < len(perturb_functions):\n",
    "                                perturb_func = perturb_functions[ax_i]\n",
    "                                data_i = data[(data[\"perturb_function\"]==perturb_func)].copy()\n",
    "                                sns.lineplot(data=data_i, x=\"severity\", y=\"AUROC\", hue=\"variant\", ax=ax, style=\"variant\", \n",
    "                                             marker=\"o\", errorbar=None)\n",
    "                                \n",
    "                                ax.set_title(f\"Perturbation={perturb_func}\")\n",
    "                                ax.set_ylabel(\"AUROC\")\n",
    "                                ax.set_xlabel(\"Severity level\")\n",
    "                                ax.set_xlim(0, 5.2)\n",
    "                                ax.legend(loc=\"lower left\", ncols=4)\n",
    "                            else:\n",
    "                                ax.axis(\"off\")\n",
    "\n",
    "                        plt.suptitle(f\"OoD Detector performance - AUROC with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}, OoD detector={score_func}\")\n",
    "                        plt.savefig(os.path.join(save_dir, f\"{benchmark.lower()}_{model_name}_{score_func}_auroc_severity.png\"))\n",
    "                        plt.close(\"all\")\n",
    "\n",
    "                        fig, axes = plt.subplots(ncols=n_cols, nrows=n_rows, figsize=(n_cols*6, n_rows*6), layout=\"constrained\", sharey=True)\n",
    "                        axes = axes.flatten()\n",
    "                        for ax_i, ax in enumerate(axes):\n",
    "                            if ax_i < len(perturb_functions):\n",
    "                                perturb_func = perturb_functions[ax_i]\n",
    "                                data_i = data[(data[\"perturb_function\"]==perturb_func)].copy()\n",
    "                                sns.lineplot(data=data_i, x=\"severity\", y=\"AUPR_IN\", hue=\"variant\", ax=ax, style=\"variant\", \n",
    "                                             marker=\"o\", errorbar=None)\n",
    "                                \n",
    "                                ax.set_title(f\"Perturbation={perturb_func}\")\n",
    "                                ax.set_ylabel(\"AUPR\")\n",
    "                                ax.set_xlabel(\"Severity level\")\n",
    "                                ax.set_xlim(0, 4.2)\n",
    "                                ax.legend(loc=\"lower left\", ncols=4)\n",
    "                            else:\n",
    "                                ax.axis(\"off\")\n",
    "\n",
    "                        plt.suptitle(f\"OoD Detector performance - AUPR with increasing severity levels of perturbations.\\nBenchmark={benchmark}, Model={model_name}, OoD detector={score_func}\")\n",
    "                        plt.savefig(os.path.join(save_dir, f\"{benchmark.lower()}_{model_name}_{score_func}_aupr_severity.png\"))\n",
    "                        plt.close(\"all\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
